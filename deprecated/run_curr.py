#å¯èƒ½æ˜¯ä¸­é—´çŠ¶æ€çš„run.pyï¼Œ
import numpy as np
import torch
import torch.nn as nn
import argparse
from util import load_data_n_model
import time
import os  # å¼•å…¥ os æ¨¡å—


# train_one_epoch å’Œ test_one_epoch å‡½æ•°ä¸ä¸Šä¸€ä¸ªå›ç­”ä¸­çš„ç‰ˆæœ¬ç›¸åŒ
# è¿™é‡Œä¸ºäº†å®Œæ•´æ€§å†æ¬¡åŒ…å«å®ƒä»¬

def train_one_epoch(model, tensor_loader, criterion, device, optimizer):
    model.train()
    epoch_loss = 0
    epoch_accuracy = 0
    num_samples = 0

    for data in tensor_loader:
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
        labels = labels.type(torch.LongTensor)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item() * inputs.size(0)
        predict_y = torch.argmax(outputs, dim=1)
        epoch_accuracy += (predict_y == labels).sum().item()
        num_samples += labels.size(0)

    epoch_loss = epoch_loss / num_samples
    epoch_accuracy = epoch_accuracy / num_samples
    return epoch_loss, epoch_accuracy


def test_one_epoch(model, tensor_loader, criterion, device):
    model.eval()
    test_acc = 0.0
    test_loss = 0.0
    num_samples = 0

    with torch.no_grad():
        for data in tensor_loader:
            inputs, labels = data
            inputs = inputs.to(device)
            labels = labels.to(device)
            labels = labels.type(torch.LongTensor)

            outputs = model(inputs)
            outputs = outputs.type(torch.FloatTensor)
            outputs.to(device)
            loss = criterion(outputs, labels)

            predict_y = torch.argmax(outputs, dim=1)
            test_acc += (predict_y == labels).sum().item()
            test_loss += loss.item() * inputs.size(0)
            num_samples += labels.size(0)

    test_acc = test_acc / num_samples
    test_loss = test_loss / num_samples
    return test_loss, test_acc


def main():
    root = '../datasets/'
    parser = argparse.ArgumentParser('WiFi Imaging Benchmark')
    parser.add_argument('--dataset', choices=['UT_HAR_data', 'NTU-Fi-HumanID', 'NTU-Fi_HAR', 'Widar'])
    parser.add_argument('--model',
                        choices=['MLP', 'LeNet', 'ResNet18', 'ResNet50', 'ResNet101', 'RNN', 'GRU', 'LSTM', 'BiLSTM',
                                 'CNN+GRU', 'ViT'])
    args = parser.parse_args()

    train_loader, test_loader, model, train_epoch = load_data_n_model(args.dataset, args.model, root)
    criterion = nn.CrossEntropyLoss()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    # ==================== æ–°å¢ï¼šç­‰é—´éš”ä¿å­˜é€»è¾‘ ====================
    # 1. åˆ›å»ºä¿å­˜ç›®å½•
    save_dir_base = 'saved_models_checkpoints'
    # ä¸ºæ¯æ¬¡å®éªŒåˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„å­æ–‡ä»¶å¤¹
    experiment_name = f'{args.dataset}_{args.model}'
    save_dir = os.path.join(save_dir_base, experiment_name)
    os.makedirs(save_dir, exist_ok=True)

    # 2. è®¡ç®—ä¿å­˜é—´éš”å’Œä¿å­˜ç‚¹
    num_saves = 10
    if train_epoch < num_saves:
        # å¦‚æœæ€»epochæ•°å°äº10ï¼Œåˆ™æ¯ä¸ªepochéƒ½ä¿å­˜
        save_interval = 1
    else:
        save_interval = train_epoch // num_saves

    # åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰éœ€è¦ä¿å­˜çš„epochç¼–å·çš„é›†åˆï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥æ‰¾
    save_epochs = set(range(save_interval, train_epoch + 1, save_interval))
    # ç¡®ä¿æœ€åä¸€ä¸ªepochæ€»æ˜¯è¢«ä¿å­˜
    save_epochs.add(train_epoch)
    print(f"æ¨¡å‹å°†ä¼šåœ¨ä»¥ä¸‹Epochç»“æŸæ—¶ä¿å­˜: {sorted(list(save_epochs))}")
    # ==========================================================

    # --- è®­ç»ƒä¸»å¾ªç¯ ---
    total_train_start = time.time()
    for epoch in range(1, train_epoch + 1):  # å¾ªç¯ä»1å¼€å§‹ï¼Œæ–¹ä¾¿ä¸epochç¼–å·å¯¹åº”
        print(f"--- Epoch {epoch}/{train_epoch} ---")

        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, device, optimizer)
        print(f"Train -> Loss: {train_loss:.5f}, Accuracy: {train_acc:.4f}")

        test_loss, test_acc = test_one_epoch(model, test_loader, criterion, device)
        print(f"Test/Validation -> Loss: {test_loss:.5f}, Accuracy: {test_acc:.4f}")

        # --- æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ä¿å­˜ç‚¹ ---
        if epoch in save_epochs:
            model_save_path = os.path.join(save_dir, f'model_epoch_{epoch}.pth')
            print(f"ğŸ’¾ åˆ°è¾¾ä¿å­˜ç‚¹ï¼Œæ­£åœ¨ä¿å­˜æ¨¡å‹åˆ°: {model_save_path}")
            torch.save(model.state_dict(), model_save_path)

    total_train_end = time.time()
    print("\n--- è®­ç»ƒå®Œæˆ ---")
    print(f"â±ï¸ æ€»è®­ç»ƒè€—æ—¶ï¼š{total_train_end - total_train_start:.2f} ç§’")
    print(f"ğŸ’¾ æ‰€æœ‰æ£€æŸ¥ç‚¹å·²ä¿å­˜åœ¨ç›®å½•: {save_dir}")


if __name__ == "__main__":
    main()