import os  # å¼•å…¥ os æ¨¡å—
# ==================== è§£å†³ num_workers å’Œ numpy çš„å†²çª ====================
#ä¸ºäº†è®¾ç½®è¿›ç¨‹ä¸ºå•çº¿ç¨‹ï¼Œå‡å°‘cpuå ç”¨
# æ˜ç¡®æ§åˆ¶ OpenBLAS çš„çº¿ç¨‹æ•°ï¼Œè¿™æ˜¯ä½ å½“å‰NumPyçš„ä¸»è¦åç«¯
os.environ['OPENBLAS_NUM_THREADS'] = '1'
# OpenBLAS å†…éƒ¨ä½¿ç”¨ OpenMPï¼Œæ‰€ä»¥è¿™ä¸ªä¹Ÿå¾ˆé‡è¦
os.environ['OMP_NUM_THREADS'] = '1'
# ç”±äºä½ çš„numpyæ²¡æœ‰é“¾æ¥MKLï¼Œè¿™ä¸¤ä¸ªå˜é‡å¯ä»¥ä¸è®¾ï¼Œä½†è®¾äº†ä¹Ÿæ— å®³ï¼Œå¯ä»¥ä¿ç•™ä»¥é˜²ä¸‡ä¸€æœªæ¥æ›´æ”¹ç¯å¢ƒ
os.environ['MKL_NUM_THREADS'] = '1'
# è¿™ä¸ªé€šå¸¸æ˜¯macOSç‰¹æœ‰çš„ï¼ŒLinuxæœåŠ¡å™¨åŸºæœ¬ç”¨ä¸åˆ°ï¼Œä½†ä¿ç•™æ— å®³
os.environ['VECLIB_MAXIMUM_THREADS'] = '1'
# å¦‚æœä½ ç¡®å®šä¸ä½¿ç”¨BLISï¼Œè¿™ä¸ªå¯ä»¥ä¸è®¾ï¼Œä¿ç•™ä¹Ÿæ— å®³
os.environ['BLIS_NUM_THREADS'] = '1'
os.environ['NUMEXPR_NUM_THREADS'] = '1' # æœ‰æ—¶ä¹Ÿéœ€è¦è¿™ä¸ª
# =========================================================================
import numpy as np
import torch
#ä¸ºäº†è®¾ç½®è¿›ç¨‹ä¸ºå•çº¿ç¨‹ï¼Œå‡å°‘cpuå ç”¨
torch.set_num_threads(1)
import torch.nn as nn
import argparse
from util import load_data_n_model
import time
import csv # 1. å¼•å…¥ csv æ¨¡å—
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.cuda.amp import autocast  # è®°å¾—åŠ ä¸Šè¿™ä¸ª import


def is_dist():
    return dist.is_available() and dist.is_initialized()

def get_rank():
    return dist.get_rank() if is_dist() else 0

def is_main():
    return get_rank() == 0



# train_one_epoch å’Œ test_one_epoch å‡½æ•°ä¸ä¸Šä¸€ä¸ªå›ç­”ä¸­çš„ç‰ˆæœ¬ç›¸åŒ
# è¿™é‡Œä¸ºäº†å®Œæ•´æ€§å†æ¬¡åŒ…å«å®ƒä»¬

'''def train_one_epoch(model, tensor_loader, criterion, device, optimizer):
    model.train()
    epoch_loss = 0
    epoch_accuracy = 0
    num_samples = 0

    for data in tensor_loader:
        inputs, labels = data
        inputs = inputs.to(device, dtype=torch.float32)
        labels = labels.to(device, dtype=torch.long)
        #labels = labels.type(torch.LongTensor)

        optimizer.zero_grad()
        outputs = model(inputs)
        #outputs = outputs.to(device)
        #outputs = outputs.type(torch.FloatTensor)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item() * inputs.size(0)
        predict_y = torch.argmax(outputs, dim=1)
        epoch_accuracy += (predict_y == labels).sum().item()
        num_samples += labels.size(0)

    epoch_loss = epoch_loss / num_samples
    epoch_accuracy = epoch_accuracy / num_samples
    return epoch_loss, epoch_accuracy'''
use_amp = True  # æ§åˆ¶æ˜¯å¦å¯ç”¨ AMPï¼ˆé»˜è®¤å¯ç”¨ï¼‰

def train_one_epoch(
    model, tensor_loader, criterion, device, optimizer,
    is_rec: int = 0, criterion_rec=None, alpha: float = 0.5,
    lam_miss=2.0,beta=0.1,log_parts=False,
    grad_check=False           # æ˜¯å¦æ£€æŸ¥æ¢¯åº¦/å‚æ•°æ˜¯å¦åœ¨æ›´æ–°ï¼ˆdebug ç”¨ï¼‰
):
    model.train()
    epoch_loss = 0.0
    epoch_correct = 0
    num_samples = 0
    # --- [æ–°å¢] loss åˆ†é‡ç»Ÿè®¡ ---
    sum_ce = 0.0
    sum_miss_term = 0.0
    sum_known_term = 0.0
    sum_miss_ratio = 0.0
    sum_scale = 0.0
    sum_mse_all_equiv = 0.0
    part_cnt = 0


    first_param_before = None
    if grad_check:
        # ç”¨æ¥éªŒè¯ optimizer çœŸçš„åœ¨æ›´æ–°å‚æ•°
        first_param_before = next(model.parameters()).detach().clone()

    for batch in tensor_loader:
        # ---- 1) æ¬åˆ° deviceï¼ˆä¿æŒ dtype æ­£ç¡®ï¼‰
        optimizer.zero_grad(set_to_none=True)
        if int(is_rec) == 0:
            inputs, labels = batch
            inputs = inputs.to(device, dtype=torch.float32, non_blocking=True)
            labels = labels.to(device, dtype=torch.long, non_blocking=True)
            '''outputs = model(inputs)
            loss = criterion(outputs, labels)'''
            # ä½¿ç”¨ autocast æ¥å¯ç”¨ bf16
            with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=use_amp):
                outputs = model(inputs)
            loss = criterion(outputs, labels)
        else:
            inputs, mask, labels, inputs_gt = batch
            inputs = inputs.to(device, dtype=torch.float32, non_blocking=True)
            mask = mask.to(device, dtype=torch.float32, non_blocking=True)
            labels = labels.to(device, dtype=torch.long, non_blocking=True)
            inputs_gt = inputs_gt.to(device, dtype=torch.float32, non_blocking=True)
            # ä½¿ç”¨ autocast æ¥å¯ç”¨ bf16
            with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=use_amp):
                outputs, x_recon = model(inputs, mask)
                # loss = criterion(outputs, labels) + float(alpha) * criterion_rec(x_recon, inputs_gt)
                # å°† loss è®¡ç®—æ”¾åœ¨ fp32
            x_recon_fp32 = x_recon.float()
            inputs_gt_fp32 = inputs_gt.float()
            m = mask.to(dtype=x_recon_fp32.dtype).clamp(0.0, 1.0)
            miss = 1.0 - m
            diff = (x_recon_fp32 - inputs_gt_fp32)
            mse_miss = (diff.mul(miss)).pow(2).sum() / (miss.sum() + 1e-8)
            mse_known = (diff.mul(m)).pow(2).sum() / (m.sum() + 1e-8)

            # miss_ratio = Nmiss / Nallï¼ˆè¿™æ˜¯ä½ è¯´çš„â€œå æ¯”éšé‡‡æ ·ç‡å˜â€çš„å…³é”®ï¼‰
            Nall = float(m.numel())
            miss_ratio = miss.sum() / (Nall + 1e-8)
            known_ratio = 1.0 - miss_ratio
            ce = criterion(outputs.float(), labels)
            loss = ce + lam_miss *  (miss_ratio * mse_miss)  + beta * (known_ratio * mse_known)
            #loss = ce + lam_miss *  (mse_miss)  + beta * (mse_known)

            if log_parts:
                # miss_ratio = Nmiss / Nall
                miss_ratio = (miss.sum() / (m.numel() + 1e-8)).detach()
                scale = ((m.numel()) / (miss.sum() + 1e-8)).detach()  # Nall/Nmiss
                mse_all_equiv = (mse_miss * miss_ratio).detach()      # â‰ˆ old MSE_all (knownè¯¯å·®â‰ˆ0æ—¶)

                sum_ce += ce.detach().float().item()
                sum_miss_term += (lam_miss * mse_miss).detach().float().item()
                sum_known_term += (beta * mse_known).detach().float().item()
                sum_miss_ratio += miss_ratio.float().item()
                sum_scale += scale.float().item()
                sum_mse_all_equiv += mse_all_equiv.float().item()
                part_cnt += 1

        loss.backward()
        optimizer.step()

        # ---- 4) ç»Ÿè®¡ epoch æŒ‡æ ‡
        bs = inputs.size(0)
        epoch_loss += loss.item() * bs
        pred = outputs.argmax(dim=1)
        epoch_correct += (pred == labels).sum().item()
        num_samples += bs


    if num_samples == 0:
        return 0.0, 0.0
    if is_dist():
        t = torch.tensor([epoch_loss, epoch_correct, num_samples],
                         device=device, dtype=torch.float64)
        dist.all_reduce(t, op=dist.ReduceOp.SUM)
        epoch_loss, epoch_correct, num_samples = t.tolist()
    epoch_loss = epoch_loss / num_samples
    epoch_accuracy = epoch_correct / num_samples

    if grad_check and first_param_before is not None:
        with torch.no_grad():
            first_param_after = next(model.parameters()).detach()
            delta = (first_param_after - first_param_before).abs().mean().item()
        if is_main():print(f"[grad_check] first_param abs-mean delta = {delta:.6e}")
    # --- [æ–°å¢] DDP èšåˆ + æ‰“å° ---
    if log_parts and part_cnt > 0:
        if is_dist():
            t = torch.tensor(
                [sum_ce, sum_miss_term, sum_known_term, sum_miss_ratio, sum_scale, sum_mse_all_equiv, float(part_cnt)],
                device=device, dtype=torch.float64
            )
            dist.all_reduce(t, op=dist.ReduceOp.SUM)
            sum_ce, sum_miss_term, sum_known_term, sum_miss_ratio, sum_scale, sum_mse_all_equiv, part_cnt = t.tolist()

        if is_main():
            denom = max(1.0, part_cnt)
            ce_m = sum_ce / denom
            miss_m = sum_miss_term / denom
            known_m = sum_known_term / denom
            mr = sum_miss_ratio / denom
            sc = sum_scale / denom
            mse_all_eq = sum_mse_all_equiv / denom
            # old 0.5*MSE_all ç­‰æ•ˆé¡¹
            old_like = 0.5 * mse_all_eq
            print(
                f"[loss_parts] miss_ratio={mr:.4f}  Nall/Nmiss={sc:.2f}  "
                f"CE={ce_m:.4f}  lam*mse_miss={miss_m:.4f}  beta*mse_known={known_m:.4f}  "
                f"mse_all_equiv={mse_all_eq:.6f}  old_like(0.5*MSE_all)={old_like:.6f}"
            )

    return epoch_loss, epoch_accuracy


def test_one_epoch(model, tensor_loader, criterion, device,
                   is_rec: int = 0, criterion_rec=None, alpha: float = 0.5,lam_miss=2.0,beta=0.1,):
    model.eval()
    total_loss, total_correct, num_samples = 0.0, 0, 0

    with torch.no_grad():
        for batch in tensor_loader:
            if int(is_rec) == 0:
                inputs, labels = batch
                inputs = inputs.to(device, dtype=torch.float32, non_blocking=True)
                labels = labels.to(device, dtype=torch.long, non_blocking=True)
                # ä½¿ç”¨ autocast å¯ç”¨ bf16
                with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=use_amp):
                    outputs = model(inputs)
                loss = criterion(outputs, labels)

            else:
                inputs, mask, labels, inputs_gt = batch
                inputs = inputs.to(device, dtype=torch.float32, non_blocking=True)
                mask = mask.to(device, dtype=torch.float32, non_blocking=True)
                labels = labels.to(device, dtype=torch.long, non_blocking=True)
                inputs_gt = inputs_gt.to(device, dtype=torch.float32, non_blocking=True)
                with torch.autocast(device_type="cuda", dtype=torch.bfloat16, enabled=use_amp):
                    outputs, x_recon = model(inputs, mask)
                    # loss = criterion(outputs, labels) + float(alpha) * criterion_rec(x_recon, inputs_gt)
                # å°† loss è®¡ç®—æ”¾åœ¨ fp32
                x_recon_fp32 = x_recon.float()
                inputs_gt_fp32 = inputs_gt.float()
                m = mask.to(dtype=x_recon_fp32.dtype).clamp(0.0, 1.0)
                miss = 1.0 - m
                diff = (x_recon_fp32 - inputs_gt_fp32)
                mse_miss = (diff.mul(miss)).pow(2).sum() / (miss.sum() + 1e-8)
                mse_known = (diff.mul(m)).pow(2).sum() / (m.sum() + 1e-8)
                ce = criterion(outputs, labels)
                Nall = float(m.numel())
                miss_ratio = miss.sum() / (Nall + 1e-8)
                known_ratio = 1.0 - miss_ratio
                loss = ce + lam_miss * (miss_ratio * mse_miss) + beta * (known_ratio * mse_known)
                #loss = ce + lam_miss * mse_miss + beta * mse_known
            bs = labels.size(0)
            total_loss += loss.item() * bs
            total_correct += (outputs.argmax(dim=1) == labels).sum().item()
            num_samples += bs
        if num_samples == 0:
            return 0.0, 0.0
        if is_dist():
            t = torch.tensor([total_loss, float(total_correct), float(num_samples)],
                             device=device, dtype=torch.float64)
            dist.all_reduce(t, op=dist.ReduceOp.SUM)
            total_loss, total_correct, num_samples = t.tolist()
        return total_loss / num_samples, total_correct / num_samples


def save_metrics_to_csv(filepath, history):
    """
    å°†æ€§èƒ½å†å²è®°å½•ï¼ˆä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼‰ä¿å­˜åˆ°CSVæ–‡ä»¶ã€‚
    Args:
        filepath (str): CSVæ–‡ä»¶çš„å®Œæ•´è·¯å¾„ã€‚
        history (list of dict): åŒ…å« 'epoch', 'loss', 'accuracy' çš„å­—å…¸åˆ—è¡¨ã€‚
    """
    if not history:
        return

    # ä½¿ç”¨ 'w' æ¨¡å¼æ‰“å¼€æ–‡ä»¶ï¼Œnewline='' æ˜¯csvæ¨¡å—çš„æ¨èåšæ³•
    with open(filepath, 'w', newline='') as f:
        # å®šä¹‰CSVæ–‡ä»¶çš„åˆ—åï¼Œä¸historyå­—å…¸ä¸­çš„é”®å¯¹åº”
        fieldnames = ['epoch', 'loss', 'accuracy']
        writer = csv.DictWriter(f, fieldnames=fieldnames)

        # å†™å…¥è¡¨å¤´
        writer.writeheader()
        # å†™å…¥æ‰€æœ‰è¡Œæ•°æ®
        writer.writerows(history)

def main():
    root = '../datasets/sense-fi/'
    if not os.path.isdir(root):
        if is_main():
            print(f"é”™è¯¯: æ•°æ®é›†æ ¹ç›®å½• '{root}' æœªæ‰¾åˆ°ã€‚")
            print("è¯·ç¡®è®¤æ‚¨çš„è„šæœ¬ï¼ˆrun.pyï¼‰æ˜¯å¦åœ¨ 'code/sense-fi/' æ–‡ä»¶å¤¹ä¸‹ï¼Œ")
            print("å¹¶ä¸” 'datasets' æ–‡ä»¶å¤¹åœ¨ 'code/' çš„ä¸Šä¸€çº§ç›®å½•ã€‚")
        return
    parser = argparse.ArgumentParser('WiFi Imaging Benchmark')
    parser.add_argument('--dataset', choices = ['UT_HAR_data','NTU-Fi-HumanID','NTU-Fi_HAR','Widar','Widar_digit_amp','Widar_digit_conj'])
    parser.add_argument('--model', choices = ['MLP','LeNet','ResNet18','ResNet50','ResNet101','RNN','GRU','LSTM','BiLSTM', 'CNN+GRU','ViT'])
    # æ–°å¢çš„å‚æ•°ï¼Œç”¨äºè‡ªå®šä¹‰å®éªŒåç§°ï¼Œå¹¶è®¾ä¸ºå¿…å¡«é¡¹
    #parser.add_argument('--exp_name', required=True, type=str, help='è‡ªå®šä¹‰å®éªŒåç§°ï¼Œå°†ç”¨äºåˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•ã€‚')
    parser.add_argument('--sample_rate', type=float, default=1.0, help='äºŒæ¬¡é™é‡‡æ ·çš„æ¯”ä¾‹ (0.05åˆ°1.0)ï¼Œå¯¹åº”25Hzåˆ°500Hzã€‚é»˜è®¤ä¸º1.0ï¼Œå³ä¸è¿›è¡ŒäºŒæ¬¡é‡‡æ ·ã€‚')
    parser.add_argument('--sample_method', type=str,default='uniform_nearest',choices=['uniform_nearest', 'equidistant', 'gaussian', 'poisson', 'trafficlike'],help='é™é‡‡æ ·æ–¹æ³•ã€‚é»˜è®¤ä¸º "uniform_nearest"ã€‚')
    parser.add_argument('--interpolation', type=str,default='linear',choices=['linear', 'cubic', 'nearest', 'idw', 'rbf','spline','akima'],help='å‡é‡‡æ ·æ—¶ä½¿ç”¨çš„æ’å€¼æ–¹æ³•ã€‚é»˜è®¤ä¸º "linear"ã€‚')
    parser.add_argument('--use_energy_input', type=int, default=1, choices=[0, 1],help='æ˜¯å¦ä½¿ç”¨èƒ½é‡ä¿¡æ¯ (1:æ˜¯, 0:å¦)ã€‚é»˜è®¤ä¸º 1 (æ˜¯)ã€‚')
    parser.add_argument('--use_mask_0', type=int, default=0, choices=[0, 1 , 2],help='æ˜¯å¦ä½¿ç”¨ mask_0 (1:æ˜¯, 0:å¦,2:ä¸maskç›´æ¥returné™é‡‡æ ·åçš„)ã€‚é»˜è®¤ä¸º 0 (å¦)ã€‚')
    parser.add_argument('--traffic_train_pt', type=str, default='/home/cxy/data/code/datasets/sense-fi/Widar_digit/mask_10_90Hz_random/train.pt', help='trafficlike train masks .pt')
    parser.add_argument('--traffic_test_pt', type=str, default='/home/cxy/data/code/datasets/sense-fi/Widar_digit/mask_10_90Hz_random/test.pt', help='trafficlike test masks .pt')
    # æ–°å¢ä¸¤ä¸ªå‚æ•°ï¼Œç”¨äºæ¥æ”¶å®Œæ•´çš„ä¿å­˜ç›®å½•
    parser.add_argument('--model_save_dir', required=True, type=str, help='æ¨¡å‹æ£€æŸ¥ç‚¹çš„å®Œæ•´ä¿å­˜ç›®å½•ã€‚')
    parser.add_argument('--metrics_save_dir', required=True, type=str, help='æ€§èƒ½æŒ‡æ ‡æ–‡ä»¶çš„å®Œæ•´ä¿å­˜ç›®å½•ã€‚')
    parser.add_argument('--is_rec', type=int, default=0, choices=[0, 1], help='1: é‡å»º+åˆ†ç±»ï¼›0: ä»…åˆ†ç±»')
    parser.add_argument('--rec_alpha', type=float, default=0.5, help='é‡å»ºæŸå¤±æƒé‡')
    parser.add_argument('--csdc_blocks', type=int, default=1, help='é‡å»ºblocksæ•°é‡')
    parser.add_argument('--rec_model', type=str, default='csdc', choices=['csdc', 'istanet','mabf','mabf_c','mabf_1d_mix','mabf2','fista', 'fista_fft', 'fista_dct','fista_blockfft'], help='é‡å»ºæ¨¡å‹ç±»å‹')
    parser.add_argument('--global_batch_size', type=int, default=128, help='å…¨å±€batch(æ‰€æœ‰GPUåŠ èµ·æ¥)')
    parser.add_argument('--num_workers_train', type=int, default=6)
    parser.add_argument('--num_workers_test', type=int, default=2)
    parser.add_argument('--lam_miss', type=float, default=1.0, help='é‡å»ºæŸå¤±ä¸­ç¼ºå¤±éƒ¨åˆ†çš„æƒé‡')
    parser.add_argument('--beta', type=float, default=0.0, help='é‡å»ºæŸå¤±ä¸­å·²çŸ¥éƒ¨åˆ†çš„æƒé‡')
    args = parser.parse_args()
    # ---- DDP init (torchrun ä¼šè®¾ç½®è¿™äº›ç¯å¢ƒå˜é‡) ----
    ddp = ("RANK" in os.environ) and ("WORLD_SIZE" in os.environ)
    if ddp:
        dist.init_process_group(backend="nccl", init_method="env://")
        local_rank = int(os.environ["LOCAL_RANK"])
        torch.cuda.set_device(local_rank)
        device = torch.device("cuda", local_rank)
        world_size = dist.get_world_size()
        rank = dist.get_rank()
    else:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        world_size = 1
        rank = 0

    # ---- å…¨å±€128 => æ¯å¡ batch = 128/world_size ----
    if args.global_batch_size % world_size != 0:
        raise ValueError(f"global_batch_size={args.global_batch_size} ä¸èƒ½è¢« world_size={world_size} æ•´é™¤")
    per_gpu_bs = args.global_batch_size // world_size
    train_loader, test_loader, model, train_epoch = load_data_n_model(
        args.dataset, args.model, root,
        args.sample_rate, args.sample_method, args.interpolation,
        args.use_energy_input, args.use_mask_0,
        args.is_rec, args.csdc_blocks, args.rec_model,
        batch_size=per_gpu_bs,
        num_workers_train=args.num_workers_train,
        num_workers_test=args.num_workers_test,
        distributed=ddp, rank=rank, world_size=world_size,
        traffic_train_pt=args.traffic_train_pt,
        traffic_test_pt=args.traffic_test_pt
    )

    #train_loader, test_loader, model, train_epoch = load_data_n_model(args.dataset, args.model, root,args.sample_rate, args.sample_method ,args.interpolation,args.use_energy_input ,args.use_mask_0 ,args.is_rec,args.csdc_blocks)
    criterion = nn.CrossEntropyLoss()
    criterion_rec = nn.MSELoss(reduction='mean') if args.is_rec else None

    #device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    if ddp:
        model = DDP(model, device_ids=[local_rank], output_device=local_rank)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)


    # --- ç›®å½•åˆ›å»º ---
    # ç°åœ¨ run.py åªè´Ÿè´£ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œä¸å†æ„å»ºå®ƒ
    os.makedirs(args.model_save_dir, exist_ok=True)
    os.makedirs(args.metrics_save_dir, exist_ok=True)
    if is_main():
        print(f"âœ… æ¨¡å‹å°†ä¿å­˜è‡³: {os.path.abspath(args.model_save_dir)}")
        print(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡å°†ä¿å­˜è‡³: {os.path.abspath(args.metrics_save_dir)}")
    # ================================================================
    # 2. è®¡ç®—ä¿å­˜é—´éš”å’Œä¿å­˜ç‚¹
    num_saves = 4
    if train_epoch < num_saves:
        # å¦‚æœæ€»epochæ•°å°äº10ï¼Œåˆ™æ¯ä¸ªepochéƒ½ä¿å­˜
        save_interval = 1
    else:
        save_interval = train_epoch // num_saves

    # åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰éœ€è¦ä¿å­˜çš„epochç¼–å·çš„é›†åˆï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥æ‰¾
    save_epochs = set(range(save_interval, train_epoch + 1, save_interval))
    # ç¡®ä¿æœ€åä¸€ä¸ªepochæ€»æ˜¯è¢«ä¿å­˜
    save_epochs.add(train_epoch)

    if is_main():print(f"æ¨¡å‹å°†ä¼šåœ¨ä»¥ä¸‹Epochç»“æŸæ—¶ä¿å­˜: {sorted(list(save_epochs))}")
    # ==========================================================

    # ==================== 4. æ–°å¢ï¼šåˆå§‹åŒ–å†å²è®°å½•åˆ—è¡¨ ====================
    train_history = []
    test_history = []

    # å›ºå®šä¸€ä»½éªŒè¯æ©ç å­é›†ï¼ˆç”¨äºæ—©åœæ›´ç¨³å®šï¼‰
    if hasattr(test_loader.dataset, "set_rate_filter"):
        test_loader.dataset.set_rate_filter(None)
    if hasattr(test_loader.dataset, "set_eval_subset"):
        test_loader.dataset.set_eval_subset(len(test_loader.dataset), seed=0)

    # [æ–°å¢] æ—©åœç›¸å…³çš„å˜é‡
    best_test_acc = 0.0  # è®°å½•å†å²æœ€ä½³å‡†ç¡®ç‡
    patience = 20  # å®¹å¿åº¦ï¼šå¦‚æœ 20 ä¸ª epoch æ²¡æå‡å°±åœæ­¢
    patience_counter = 0  # è®¡æ•°å™¨
    # ===================================================
    # --- è®­ç»ƒä¸»å¾ªç¯ ---
    total_train_start = time.time()
    for epoch in range(1, train_epoch + 1):  # å¾ªç¯ä»1å¼€å§‹ï¼Œæ–¹ä¾¿ä¸epochç¼–å·å¯¹åº”
        if ddp and hasattr(train_loader.sampler, "set_epoch"):
            train_loader.sampler.set_epoch(epoch)
        if hasattr(train_loader.dataset, "set_epoch"):
            train_loader.dataset.set_epoch(epoch)
        if is_main():print(f"--- Epoch {epoch}/{train_epoch} ---")
        epoch_start = time.time()
        log_parts = (epoch <= 3)# å‰3ä¸ªepochæ‰“å°lossåˆ†é‡
        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, device, optimizer,
                                                is_rec=args.is_rec, criterion_rec=criterion_rec, alpha=args.rec_alpha,lam_miss=args.lam_miss,beta=args.beta,log_parts=log_parts)
        if is_main():print(f"Train -> Loss: {train_loss:.5f}, Accuracy: {train_acc:.4f}")

        test_loss, test_acc = test_one_epoch(model, test_loader, criterion, device,
                                             is_rec=args.is_rec, criterion_rec=criterion_rec, alpha=args.rec_alpha, lam_miss=args.lam_miss,beta=args.beta)
        if is_main():print(f"Test/Validation -> Loss: {test_loss:.5f}, Accuracy: {test_acc:.4f}")
        if is_main():
            epoch_time = time.time() - epoch_start
            print(f"Epoch time: {epoch_time:.2f} s")

        # ==================== 5. æ–°å¢ï¼šæ”¶é›†å½“å‰epochçš„æ•°æ® ====================
        train_history.append({'epoch': epoch, 'loss': train_loss, 'accuracy': train_acc})
        test_history.append({'epoch': epoch, 'loss': test_loss, 'accuracy': test_acc})

        # ==================== [æ ¸å¿ƒä¿®æ”¹] æ—©åœä¸æœ€ä½³æ¨¡å‹ä¿å­˜ ====================
        if test_acc > best_test_acc:
            best_test_acc = test_acc
            patience_counter = 0  # é‡ç½®è®¡æ•°å™¨

            # ä¿å­˜æœ€ä½³æ¨¡å‹ (è¦†ç›–å¼ä¿å­˜ï¼Œå§‹ç»ˆåªæœ‰ä¸€ä¸ª best_model.pth)
            # åªæœ‰å½“ Epoch > 10 ä»¥åï¼Œæ‰çœŸæ­£å¼€å§‹æ‰§è¡Œä¿å­˜ç¡¬ç›˜çš„æ“ä½œ
            if epoch > 20:
                best_model_path = os.path.join(args.model_save_dir, 'best_model.pth')
                if is_main():
                    state = model.module.state_dict() if ddp else model.state_dict()
                    torch.save(state, best_model_path)
                    print(f"ğŸŒŸ æ–°çºªå½•ï¼æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (Acc: {best_test_acc:.4f})")
            else:
                if is_main():print(f"ğŸŒŸ æ–°çºªå½• (Acc: {best_test_acc:.4f}) - è®­ç»ƒåˆæœŸæš‚ä¸ä¿å­˜")

        else:
            # åŒæ ·ï¼Œå‰ 10 ä¸ª Epoch ä¹Ÿä¸æ¶ˆè€— patienceï¼ˆå®½å®¹æœŸï¼‰
            if epoch > 20:
                patience_counter += 1
                if is_main():print(f"âš ï¸ æ€§èƒ½æœªæå‡ ({patience_counter}/{patience})")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
        if patience_counter >= patience:
            if is_main():
                print(f"\nğŸ›‘ è§¦å‘æ—©åœæœºåˆ¶ï¼æµ‹è¯•é›†å‡†ç¡®ç‡å·²è¿ç»­ {patience} ä¸ª Epoch æœªæå‡ã€‚")
                print(f"   å½“å‰æœ€ä½³å‡†ç¡®ç‡: {best_test_acc:.4f}")
                print(f"   åœ¨ Epoch {epoch} åœæ­¢è®­ç»ƒã€‚")
            break  # è·³å‡º for å¾ªç¯
        # ===================================================================

        # --- æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ä¿å­˜ç‚¹ ---#å‰é¢æœ‰ä¿å­˜æœ€ä½³æ¨¡å‹äº†ï¼Œæ‰€ä»¥è¿™é‡Œä¸å†ä¿å­˜ã€‚
        '''if epoch in save_epochs:
            model_save_path = os.path.join(args.model_save_dir, f'model_epoch_{epoch}.pth')
            print(f"ğŸ’¾ åˆ°è¾¾ä¿å­˜ç‚¹ï¼Œæ­£åœ¨ä¿å­˜æ¨¡å‹åˆ°: {model_save_path}")
            torch.save(model.state_dict(), model_save_path)'''

    total_train_end = time.time()
    if is_main():
        print("\n--- è®­ç»ƒå®Œæˆ ---")
        print(f"â±ï¸ æ€»è®­ç»ƒè€—æ—¶ï¼š{total_train_end - total_train_start:.2f} ç§’")

    # ä½¿ç”¨æ–°çš„ç›®å½•å‚æ•°æ¥æ„å»ºè·¯å¾„
    train_metrics_path = os.path.join(args.metrics_save_dir, 'train_metrics.csv')
    test_metrics_path = os.path.join(args.metrics_save_dir, 'test_metrics.csv')

    if is_main():
        print(f"ğŸ“Š æ­£åœ¨ä¿å­˜è®­ç»ƒå†å²åˆ°: {train_metrics_path}")
        save_metrics_to_csv(train_metrics_path, train_history)

    if is_main():
        print(f"ğŸ“Š æ­£åœ¨ä¿å­˜æµ‹è¯•å†å²åˆ°: {test_metrics_path}")
        save_metrics_to_csv(test_metrics_path, test_history)

    # per-rate evaluation for trafficlike masks
    if hasattr(test_loader.dataset, "get_available_rates"):
        rates = test_loader.dataset.get_available_rates()
        if rates:
            rate_history = []
            if is_main():
                print("Running per-rate evaluation...")
            for r in rates:
                if hasattr(test_loader.dataset, "set_rate_filter"):
                    test_loader.dataset.set_rate_filter(r)
                if hasattr(test_loader.dataset, "set_eval_subset"):
                    test_loader.dataset.set_eval_subset(len(test_loader.dataset), seed=1000 + int(r))
                r_loss, r_acc = test_one_epoch(model, test_loader, criterion, device,
                                               is_rec=args.is_rec, criterion_rec=criterion_rec, alpha=args.rec_alpha, lam_miss=args.lam_miss,beta=args.beta)
                if is_main():
                    print(f"[rate {r}] Loss: {r_loss:.5f}, Accuracy: {r_acc:.4f}")
                rate_history.append({'rate_hz': int(r), 'loss': r_loss, 'accuracy': r_acc})
            if hasattr(test_loader.dataset, "set_rate_filter"):
                test_loader.dataset.set_rate_filter(None)
            if hasattr(test_loader.dataset, "set_eval_subset"):
                test_loader.dataset.set_eval_subset(len(test_loader.dataset), seed=0)
            if is_main():
                rate_path = os.path.join(args.metrics_save_dir, 'test_metrics_by_rate.csv')
                with open(rate_path, 'w', newline='') as f:
                    writer = csv.DictWriter(f, fieldnames=['rate_hz', 'loss', 'accuracy'])
                    writer.writeheader()
                    writer.writerows(rate_history)
                print(f"Saved per-rate metrics to: {rate_path}")

    #print(f"ğŸ’¾ æ‰€æœ‰æ£€æŸ¥ç‚¹å·²ä¿å­˜åœ¨ç›®å½•: {args.model_save_dir}")
    if ddp:
        dist.destroy_process_group()

if __name__ == "__main__":
    main()
